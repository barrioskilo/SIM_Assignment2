---
title: | 
    | Assignment 2 - Vote Choice in Germany
    | Statistical Inference and Modelling - SIM
    | 1st Semester 2022
author: "Ander Barrio Campos, Odysseas Kyparissis"
date: "`r Sys.Date()`"
geometry: margin=2cm
fontsize: 12pt
line-height: 1.5
output: 
  pdf_document:
    includes:
      in_header: header.tex
    toc: no
    number_sections: true
    fig_width: 6
    fig_height: 4
    fig_caption: true
classoption: a4paper
editor_options: 
  chunk_output_type: console
header-includes:
- \pagenumbering{gobble}
---

\newpage

```{=latex}
\setcounter{tocdepth}{4}
\tableofcontents
```
```{=tex}
\newpage
\pagenumbering{arabic}
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Clear plots from the R plots view:
if(!is.null(dev.list())) dev.off()

# Clean workspace - No variables at the current workspace
rm(list=ls())

# Setting working directory
setwd("C:/Users/odyky/Desktop/SIM_Assignment2")
# setwd("/Users/anderbarriocampos/Desktop/UPC/SIM/Assignment2")

options(contrasts=c("contr.treatment","contr.treatment")) #Baseline category reparametrization

# Libraries loading
library(ggplot2)
library(GGally)
library(car)
library(lmtest)
library(chemometrics)
library(FactoMineR)
library(corrplot)
library(effects)
library(AER)
library(MASS)
library(egg)
library(nnet)
library(MNLpred)
```

\newpage

# Explanatory Data Analysis - EDA

## Loading Voting Data

In this part of the report, setting up the working environment and loading of the data into R are taking place. Additionally, a first look at the summary of the raw voting choice in Germany data set is taken.

```{r read}
load("gles.RData")
summary(gles)
```

## Data Types

To begin with, the types of the raw variables contained into the data set are being checked. It is clear, that the raw data set consists of 5 numerical variables and 1 categorical. On the one hand, based on the raw data types, the numeric variables are the following: *egoposition_immigration*, *ostwest*, *political_interest*, *income* and *gender*, while the categorical one is variable *vote*. On the other hand, if page 3 of the assignment statement (subsection *Variables*) is taken into account, all of the numerical variables correspond to qualitative concepts. In more detail, variables *egoposition_immigration, political_interest* and *income* (*income-satisfaction)* correspond to ordered factors, while *ostwest* and *gender* variables are binary ones. In the following sections, all the numerical variables will be transformed into labeled factors (ordered or not).

```{r rawtypes, include=FALSE}
typeof(gles$vote)
typeof(gles$egoposition_immigration)
typeof(gles$ostwest)
typeof(gles$political_interest)
typeof(gles$income)
typeof(gles$gender)
```

## Checking for Missing Data

To continue with, a check for missing data is conducted on the raw data set. Considering the summary of the data set presented before, there are no NA values in the variables of the data set. The same conclusion is derived when a check is completed for each individual variable.

```{r missingData, include=FALSE}
ll <- which( gles$vote=="NA"); length(ll)
ll <- which( gles$egoposition_immigration=="NA"); length(ll)
ll <- which( gles$ostwest=="NA"); length(ll)
ll <- which( gles$political_interest=="NA"); length(ll)
ll <- which( gles$income=="NA"); length(ll)
ll <- which( gles$gender=="NA"); length(ll)
```

## Checking for Duplicates

By checking if there are duplicate rows inside the raw data set, the result indicates that a total number of 359 occurrences of duplicates exist.

```{r checkingDuplicates}
dupli <- duplicated(gles); dupli_ind <- which(dupli); length(dupli_ind)
```

With the following command, a closer look can be taken into the values of the first 5 duplicate rows (for space saving reasons).

```{r presentDuplicate}
gles[dupli_ind,][1:5,]
```

By taking a closer look at the duplicates, one can understand that, it is logical people with the same characteristics to vote for the same party during the elections. For that reason, the duplicates are not removed or treated, but a new factor will be created in the dataset indicating if a row is a duplicate or not.

```{r createDuplicateFactor, include=FALSE}
gles$f.duplicate<-0; gles$f.duplicate[dupli_ind]<-1
gles$f.duplicate<-factor(gles$f.duplicate,labels=c("No.Duplicate","Yes.Duplicate"))
```

## Creating Factors for Qualitative Variables

In this subsection of EDA, all qualitative variables are transformed into labeled factors (nominal, ordinal and binary). All variables of the raw data set, as mentioned before, correspond to categorical ones. First of all, their unique values are presented below:

```{r uniqueValeusOfVariables}
unique(gles$vote); unique(gles$egoposition_immigration); unique(gles$ostwest)
unique(gles$political_interest); unique(gles$income); unique(gles$gender)
```

The next step includes the creation of the labeled factors based on the unique values of the categorical variables. Following the practice below, in case a categorical variable includes NA values, they will be transformed into zeros, which is an incorrect approach. In this case, once missing values check indicated that there are no missing data, proceeding with this practice does not result in erroneous data.

Additionally, it is crucial to mention here that the following variables were transformed into ordered factors: *income, political_interest* and *egoposition_immigration.* Moreover *gender, vote* and *ostwest* variables were transformed to nominal factors and finally a new nominal factor was generated, named *political_orientation.* This new variable discretize the 6 German parties into three political wings with labels *Left_Wing, Center_Wing* and *Right_Wing* respectively. In order to accomplish this discretization, page 3 of the assignment statement (subsection *Variables -* indicating the character of each political party: left, center, right) was taken into account one more time.

```{r ostwestToFactor, echo=FALSE}
gles$f.eastGermany<-0; gles$f.eastGermany[gles$ostwest=="1"]<-1
gles$f.eastGermany<-factor(gles$f.eastGermany,
                           labels=c("No.EastGermany","Yes.EastGermany"))
```

```{r genderToFactor, echo=FALSE}
gles$f.gender<-0; gles$f.gender[gles$gender=="1"]<-1
gles$f.gender<-factor(gles$f.gender, labels=c("M","F"))
```

```{r incomeToOrderedFactor, echo=FALSE}
gles$f.income <- ordered(gles$income, levels=c(0, 1, 2, 3, 4),
                         labels=c("Low.Sat", "Low_to_Medium.Sat",
                                  "Medium.Sat", "Medium_to_High.Sat",
                                  "High.Sat"))
```

```{r politicalInterestToOrderedFactor, echo=FALSE}
gles$f.political_interest <- ordered(gles$political_interest,
                                     levels=c(0, 1, 2, 3, 4),
                                     labels=c("Low.Inter",
                                              "Low_to_Medium.Inter",
                                              "Medium.Inter",
                                              "Medium_to_High.Inter",
                                              "High.Inter"))
```

```{r egoPositionToOrderedFactor, echo=FALSE}
gles$f.egoposition_immigration <- ordered(gles$egoposition_immigration,
                                     levels=c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                                     labels=c("0_Very_Open_Level.Imm",
                                              "1_Level.Imm",
                                              "2_Level.Imm",
                                              "3_Level.Imm",
                                              "4_Level.Imm",
                                              "5_Neutral_Level.Imm",
                                              "6_Level.Imm",
                                              "7_Level.Imm",
                                              "8_Level.Imm",
                                              "9_Level.Imm",
                                              "10_Very_Restrictive_Level.Imm"))
```

```{r voteToFactor, echo=FALSE}
gles$f.vote<-as.factor(gles$vote)
```

```{r voteToPoliticalOrientationFactor, echo=FALSE}
gles$f.political_orientation<-0 #center
gles$f.political_orientation[gles$vote=="Gruene" | gles$vote=="LINKE"]<-1 #left
gles$f.political_orientation[gles$vote=="AfD"]<-2 #right
gles$f.political_orientation<-factor(gles$f.political_orientation,
                                     labels=c("Center_Wing","Left_Wing",
                                              "Right_Wing"))
```

In the Polytomous Modelling chapter of the report the generation of new factors for those variables is taking place as well.

## Factor Conversion Check

After checking both manually and by executing commands on the terminal, the conversion of the categorical and numerical variables to factors has been completed correctly. In addition, while the categorical variables *vote*, *ostwest* and *gender* have been transformed into labeled factors, their old versions are discarded from the data frame (in those cases it is sure that their numerical representation does not provide any extra information). The remaining variables were not discarded in order to check if better results could be obtained by using their numerical representation in higher powers (poly function). Below the new structure of the data frame is presented.

```{r removingCHRVariables, echo=FALSE}
gles$vote <- NULL #delete vote
gles$ostwest <- NULL #delete ostwest
gles$gender <- NULL #delete gender
```

```{r glesSumm}
summary(gles)
```

## Univariate Descriptive Analysis - UDA

As it is stated in the assignment's statement, but as it was concluded in the previous subsection, data set is unbalanced and it contains individuals who mostly vote for parties belonging in the center wing of politics, followed by left wing and finally left wing respectively. The differences between the numbers of each wing are significant. More details are presented below.

### Descriptive Analysis for Numerical Variables

In this subsection, summary statistics, the standard deviation and histograms are presented for the numerical representation of the variables *egoposition_immigration*, *political_interest* and *income*.

```{r quantitativeData, echo=FALSE}
quantiData = gles[c('egoposition_immigration', 'political_interest', 'income')]
#quantiData
```

### Standard Deviation

```{r standardDeviation}
lapply(quantiData, sd)
```

```{r summaries}
summary(gles$egoposition_immigration)
summary(gles$political_interest)
summary(gles$income)
```

```{r histogramms, echo=FALSE, message=FALSE, warning = F}

hEgo <- ggplot(gles, aes(x=egoposition_immigration)) + 
  geom_histogram(color="black", fill="#00AFBB")


hPoli <-ggplot(gles, aes(x=political_interest)) + 
  geom_histogram(color="black", fill="#00AFBB")

hIncome <- ggplot(gles, aes(x=income)) + 
  geom_histogram(color="black", fill="#00AFBB")

ggarrange(hEgo, hPoli, hIncome, 
          ncol = 1, nrow = 3)
```

From the histograms, it is clear that those 1000 German citizens show interest in the political elections since most of the observations belong to categories *Medium* to *High.* The same is true for variable *income* which depicts the satisfaction of the citizens with their income. Concerning variable *egoposition_immigration* it can be seen that the plot is close to follow a normal distribution with a slight right skewness. This means that most of the citizens in the data set are *Neutral* concerning immigration while the rest of them are scattered through the rest of the variable levels, with a small trend to follow more open ideas for immigration issues.

In addition, the calculation of Spearman correlation is presented for the numerical variables. In the following graph, it is clear that there is not strong correlation between the numerical representation of the variables *egoposition_immigration, political_interest* and *income*. By checking the correlation matrix the values are extremely low.

```{r corrPlot, echo=FALSE}
M <- cor(gles[,c(1:3)],method="spearman");M #Non Parametric version
corrplot(M, method="circle")
```

### Descriptive Analysis for Categorial Variables

Moreover, bar plots are generated illustrating the content of the variables *ostwest*, *gender* and target variables *vote* and *political_orientation (*new derived factor containing *left*, *center* and *right* wings).

### Bar Plots

```{r barPlots, echo=FALSE, message=FALSE, warning = F}
gg_east <- ggplot(gles, aes(x = f.eastGermany)) + 
  geom_bar(fill = "#00AFBB", 
           color="black") +
  labs(x = "People Living in East Germany", 
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1))

gg_gender <- ggplot(gles, aes(x = f.gender)) + 
  geom_bar(fill = "#00AFBB", 
           color="black") +
  labs(x = "Gender of Individuals", 
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1))

gg_political_or <- ggplot(gles, aes(x = f.political_orientation)) + 
  geom_bar(fill = "#00AFBB", 
           color="black") +
  labs(x = "Political Orientation (New Vote Variable)", 
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1))

gg_vote <- ggplot(gles, aes(x = f.vote)) + 
  geom_bar(fill = "#00AFBB", 
           color="black") +
  labs(x = "Votes", 
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1))

ggarrange(gg_east, gg_gender, gg_political_or, gg_vote, ncol = 2, nrow = 2)
```

From the barplots, it is illustrated that most of the observations are from citizens of the Eastern Gemany, while the gender of them are balanced. In addition, there is a huge difference in the numbers of citizens voting for parties in the *center political wing* while a smaller number of them vote for the *left wing* and finally the *right* one. Finally, party wise, the one with the most votes is party *CDU/CSU,* followed by *SPD* with a small difference. At the same time Gruene, LINKE and FDP are pretty close with each other, but with approximately half of the votes of *CDU/CSU* and *SPD.*

## Outliers Detection

```{r calcQFunction, echo=FALSE}
calcQ <- function(x) {
  s.x <- summary(x)
  iqr<-s.x[5]-s.x[2]
  list(souti=s.x[2]-3*iqr, mouti=s.x[2]-1.5*iqr, min=s.x[1], q1=s.x[2], q2=s.x[3], 
       q3=s.x[5], max=s.x[6], mouts=s.x[5]+1.5*iqr, souts=s.x[5]+3*iqr ) }
```

In the following subsections both uni-variate and multivariate outliers will be detected and treated.

### Uni-variate Outliers

To start with, in the following subsection the uni-variate outliers will be detected for the numerical variables: *egoposition_immigration*, *political_interest* and *income* with the respective order. It is crucial to mention here, that only severe outliers were taken into account and not mild ones. Now, concerning variable *egoposition_immigration*, as it is depicted in the boxplot of the variable, outliers do not exist. The same result is derived after trying to detect outliers using the IQR method, which is implemented by function calcQ.

```{r uniOutEgoBoxPlot, message=FALSE, echo=FALSE, fig.height=3, fig.width=6}
boxplot(gles$egoposition_immigration, main = "Boxplot of Variable Egoposition Inmigration")
```

```{r uniOutEgoIQR, message=FALSE, echo=FALSE}
var_out<-calcQ(gles$egoposition_immigration)
llout_ego<-which((gles$egoposition_immigration<var_out$souti)|(gles$egoposition_immigration>var_out$souts))
length(llout_ego)
```

Following by, the same approach is used for variable *political_interest*.

```{r uniOutPoliBoxPlot, message=FALSE, echo=FALSE,fig.height=3, fig.width=6}
boxplot(gles$political_interest, main = "Boxplot of Variable Political Interest")
var_out<-calcQ(gles$political_interest)
llout_political<-which((gles$political_interest<var_out$souti)|(gles$political_interest>var_out$souts))
length(llout_political)
```

The results are the same, there are no severe outliers for variable *political_interest* as well. Finally, the outlier detection for the income is taking place.

```{r uniOutIncome, echo=FALSE, fig.height=3, fig.width=6}
boxplot(gles$income, main = "Boxplot of Variable Income")
var_out<-calcQ(gles$income)
abline(h=var_out$souts,col="red")
abline(h=var_out$souti,col="red")
abline(h=var_out$mouts,col="red")
llout_income<-which((gles$income<var_out$souti)|(gles$income>var_out$souts))
length(llout_income)
```

In this case, there are extreme outliers for the income variable, which are presented below (only first 10 rows out of 418 in total).

```{r incomeOutliers}
gles[llout_income,][1:10,]
table(gles$income)
```

Additionally, by taking a look at the figure and the table of occurrences for factor variable *income*, it is clear that by using the IQR method in this case, all categories except *Medium_to_High.Sat (level 3)* are considered outliers (13+28+188+189 = 418). For that reason, a new column is generated to indicate the uni-variate outliers for *income.* For now, those outliers are kept into the data set, and in the subsections below, it will be decided if it is necessary to be removed.

```{r incomeOutliersFactor, echo=FALSE}
gles$f.incomeOutliers<-0;
gles$f.incomeOutliers[gles$f.income!="Medium_to_High.Sat"]<-1
gles$f.incomeOutliers<-factor(gles$f.incomeOutliers,
                           labels=c("No.IncomeOutlier","Yes.IncomeOutlier"))
```

### Multivariate Outliers

In this subsection, an attempt for the detection of multivariate outliers took place. To start with, the calculation of the Mahalanobis distance is possible only for numerical variables. At this point, at first, an attempt to calculate the Mahalanobis distance for the numerical representation of *egoposition_immigration*, *political_interest* and *income* with a confidence interval of 95% was followed. Due to the fact that those variables create a singular matrix for the calculation of the Mahalanobis distance, its inverse matrix cannot be calculated and in that way an error is thrown. Additionally, an attempt was completed to calculate the distance for all the variables in their raw format (all variables at numerical representation), but the same problem occurred again. The Classical and Robust Mahalanobis distances could be only calculated for the combination of *egoposition_immigration* and *political_interest* variables of the data set. The results are presented in the following figure:

```{r mOutMaha, echo=FALSE}
#res.mout <- Moutlier(gles[,c(1:3)]) # Throws error -- We tried to calculate it by combining as well the numerical variables we deleted in chunq "removingCHRVariables" but the same problem happened.
res.mout <- Moutlier(gles[,c(1:2)], quantile = 0.95)
```

After calculating Mahalanobis distance at a 95% confidence interval, the cut off given is 2.447747.

```{r mOutCutOff, include=FALSE}
res.mout$cutoff
```

Then, all the observations which have a classical and a robust distance bigger than this cut off are marked as multivariate outliers (in this case the term *multivariate* refers only to *egoposition_immigration* and *political_interest* variables). After detecting them, a new factor (*f.mout*) is being created in the data set, indicating if an observation belongs to multivariate outliers or not. It can be seen in the final result that 24 observations are marked as multivariate outliers. Further analysis about them will be conducted in the following sections.

```{r mOutPlot, echo=FALSE}
par(mfrow=c(1,1))
plot( res.mout$md, res.mout$rd )
text(res.mout$md, res.mout$rd, labels=rownames(df),adj=1, cex=0.5)
abline( h=res.mout$cutoff, lwd=2, col="red")
abline( v=res.mout$cutoff, lwd=2, col="red")
```

```{r detectMout, echo=FALSE}
llmout <- which((res.mout$md > res.mout$cutoff) 
                 & (res.mout$rd > res.mout$cutoff))
gles$f.mout <- 0
gles$f.mout[llmout] <- 1
gles$f.mout <- factor( gles$f.mout, labels = c("MvOut.No","MvOut.Yes"))
```

```{r summaryMout, echo=FALSE}
summary(gles["f.mout"])
```

## Profiling of Target Variable(s)

The goal of this chapter is to discover the relationships between the explanatory variables of the data set and the target variable(s). In order to do so the calculation and presentation of interactions between the target and explanatory variables by using the library FactoMineR and Boxplots is completed.

Moreover, with the usage of the library FactoMineR and specifically the function catdes, which calculate the dependencies of a categorical variable, it is able to check the dependencies of the target variable(s) with the explanatory variables of the data set. At first, the dependency between the target variable *f.vote* and the rest of the variables will take place, followed by the same analysis for the new derived target variable *f.political_orientation*. Profiling is completed only by using the factor representation of the explanatory variables and the results are presented in the Appendix at the same subsection.

The main conclusions derived from profiling the target variables are presented here, starting from target variable *f.vote* following by the second target variable *f.political_orientation*. For variable *f.vote* the main conclusions are:

-   Party ***AfD** (right wing)* is strongly correlated with citizens who have high values for variable *egoposition_imigration* (8-10) meaning they have more far-right beliefs, they are mainly *males* with *low_political_interest* and *low_to_medium* salary satisfaction.

-   Party **CDU/CSU** *(center-right)* has strong relationship with people who are achieve levels 5 to 7 of *egoposition_imigration* meaning that they are mainly neutral with a slight orientation to *right beliefs* for immigration issues, while they present *medium political interest* and *medium salary satisfaction*.

-   Party **FDP** *(center-right)* have strong connection levels 0, 2 and 6 of *egoposition_imigration,* which is confusing. In this case, the conclusion is that maybe the data set does not contain data that will provide quality explanatory power for predicting the voting of this party.

-   Party **Gruene** *(left)* shows strong relation with level 2 of variable *egoposition_imigration,* which means that they are open for immigration issues. Additionally, most of the citizens voting this party are females with *medium_to_high political interest.*

-   Party **LINKE** *(left)*is mainly described by observations containing values of *No.EastGermany* for variable *f.eastGermany,* level 0 *(Very Open)* for variable *egoposition_imigration* and *medium income satisfaction*. Also, value Yes.EastGermany appear a lot for this party, so it can concluded that variable *f.eastGermany* will not provide explanatory power for predicting this party.

For variable *f.political_orientation* the main conclusions are:

-   **Center Political Wing** is mainly described by level 5 of variable *egoposition_imigration (Neutral),* people from East Germany (*Yes.EastGermany for variable f.eastGermany), high income satisfaction* and *medium political interest.*

-   **Left Political Wing** is strongly connected with levels 0, 2 and 3 of variable *egoposition_imigration* meaning that it is open to immigration issues, and *high salary satisfaction* (Not sure if this makes sense, but we have no information for demographics and salaries of people voting left parties in Germany)*.*

-   **Right Political Wing** is mainly connected with levels 8 and 10 for *egoposition_imigration (*far-right beliefs). Also, those observations are strongly connected with observations of *males,* with value No.EastGermany for *f.eastGermany* variable, with *low political interest* and *low to medium salary satisfaction.*

Concerning the profiling of target variables with quality metrics of the data set, like number of missing values, number of errors in data, number of univariate or multivariate outliers, is not included in detail while the data set do not contain missing or erroneous data. For the correlation of the target variables with outliers some results are presented during the profiling done by using FactoMineR (presented in Appendix) but the results are not so insightful.

# Polytomous Modelling

In this section of the report, the creation and comparison of multiple models for the prediction of probabilities for voting each party or each political wing is completed. For the sake of this assignment, the goal is to provide *three final models* following the approaches: nominal response, ordinal response and hierarchical approach. In order to do so, for nominal response model, the variable *f.vote* containing the 6 different parties will be used. For ordinal response model, *f.vote factor* will be transformed to an ordinal factor creating an ordinal relationship from far-left parties to far-right ones. More specifically, the order is the following *(f.vote_ord) -* the specific order was chosen based on page 3 of assignment's statement:

-   LINKE \> Gruene \> SPD \> FDP \> CDU/CSU \> AfD

```{r createVoteOrd, echo=FALSE}
gles$f.vote_ord <- factor(gles$f.vote, ordered = TRUE, levels = c("LINKE", "Gruene", "SPD", "FDP", "CDU/CSU", "AfD")) 
# This transformation takes place here and not in the EDA section of the report, for the reason that it was not so clear, that it was necessary, while reading the assignment statement at first. After f.vote factor was converted to an ordinal one with this command, it was checked that the conversion was completed correctly.
```

Finally, for the hierarchical approach the target variable will be *f.political_orientation* and in this case 2 nested binary outcome models will be created.

Before proceeding to modeling chapters, the split of the data set into training and test set is necessary and is conducted here.

```{r splitTrainTestSet, echo=FALSE}
set.seed(150996)

#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(gles), replace=TRUE, prob=c(0.7,0.3))
train  <- gles[sample,]
test   <- gles[!sample,]
```

## Nominal Polytomous Modeling

### Comparison of Variables' Numerical and Categorical Representation

As a first step in this subsection, it is necessary to check if variables *egoposition_immigration*, *political_interest* and *income* provide better explanatory power when they are used as numerical or categorical variables*.* In order to do so, the following approach has been used:

1.  Train a nominal polytomous target model containing only one of those variables in a continuous representation.

2.  Train a nominal polytomous target model containing only one of those variables in a continuous representation, including second, cube and quadratic exponent of the variable.

3.  Train a nominal polytomous target model containing only one of those variables in a categorical representation.

4.  Derive new factor for each variable by combining some levels of the already existed factors, and train a new model with it. The new levels are chosen below, based on the allEffects plots.

5.  Compare those 6 models and the NULL model for each variable by using anova and AIC.

6.  Keep each variable's representation that provide the best results in each case.

```{r newImmFactor, echo=FALSE}
gles$f.Imm<-0
ll<-which(gles$egoposition_immigration %in% c(1,2,3))
gles$f.Imm[ll]<-1
ll<-which(gles$egoposition_immigration %in% c(4,5,6))
gles$f.Imm[ll]<-2
ll<-which(gles$egoposition_immigration %in% c(7,8,9))
gles$f.Imm[ll]<-3
ll<-which(gles$egoposition_immigration %in% c(10))
gles$f.Imm[ll]<-4
gles$f.Imm <- factor(gles$f.Imm,labels=c("low", "low_medium", "medium", "medium_high", "high"))
gles$f.Imm <- factor(gles$f.Imm, ordered = TRUE, levels = c("low", "low_medium", "medium", "medium_high", "high"))
```

```{r newPolIntFactor, echo=FALSE}
gles$f.PolInt<-0
ll<-which(gles$political_interest %in% c(1,2,3))
gles$f.PolInt[ll]<-1
ll<-which(gles$political_interest %in% c(4))
gles$f.PolInt[ll]<-2
gles$f.PolInt <- factor(gles$f.PolInt,labels=c("low", "medium", "high"))
gles$f.PolInt <- factor(gles$f.PolInt, ordered = TRUE, levels = c("low", "medium", "high"))
```

```{r newPolIntFactor, echo=FALSE}
gles$f.IncSat<-0
ll<-which(gles$income %in% c(1))
gles$f.IncSat[ll]<-1
ll<-which(gles$income %in% c(2,3))
gles$f.IncSat[ll]<-2
ll<-which(gles$income %in% c(4))
gles$f.IncSat[ll]<-3
gles$f.IncSat <- factor(gles$f.IncSat,labels=c("low", "low_to_medium","medium", "high"))
gles$f.IncSat <- factor(gles$f.IncSat, ordered = TRUE, levels = c("low", "low_to_medium","medium", "high"))
```

```{r splitTrainTestSet2, echo=FALSE}
set.seed(150996)

#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(gles), replace=TRUE, prob=c(0.7,0.3))
train  <- gles[sample,]
test   <- gles[!sample,]
```

The results of the analysis are presented in the respective subsection of the Appendix for space saving reasons. Finally, during modelling procedure the above-mentioned variables will be used in the following forms, respectively:

-   ***egoposition_immigration**:* the new derived factor *f.Imm* will be used to represent this variable.

-   ***political_interest***: poly(political_interest,2), even if the squared form of this variable does not provide significant explanatory power (null model had pretty much the same predictability).

-   ***income*** : the new derived factor *f.IncSat* will be used to represent this variable.

## Comparison of Nominal Models

```{r baselineNullModel, echo=FALSE}
table(train$f.vote)# AfD is baseline
nm0 <-multinom(f.vote~1, data=train) # Null model
```

```{r modelTraining}
nm1 <-multinom(f.vote~ 
                 scale(poly(political_interest,2), scale = FALSE)*
                 (f.Imm +
                 f.IncSat +
                 f.eastGermany +
                 f.gender)
                 ,data= train)
summary(nm1)
nm1_step <- step(nm1)
summary(nm1_step)

AIC(nm0,nm1_step)
party_probs <- predict(nm1_step, type="probs")
tt<-table(predict(nm1_step),train$f.vote);tt #Check that the model is not predicting part times
100*sum(diag(tt))/sum(tt)
sum(residuals(nm1_step,'deviance')^2)
sum(residuals(nm1_step,'pearson')^2)

#library("ROCR")
#dadesroc<-prediction(predict(m15,type="response"),dfwork$pres)
#par(mfrow=c(1,2))
#plot(performance(dadesroc,"err"))
#plot(performance(dadesroc,"tpr","fpr"))
#abline(0,1,lty=2)

#library(cvAUC)
#AUC(predict(m15,type="response"),dfwork$pres)
```

## Ordinal Polytomous Modeling

## Hierarchical Modeling

# Appendix

## EDA

## Profiling of Target Variable(s)

In the following plots the levels of variable *f.vote* and *f.political_orientation* follow the structure presented below.

```{r mapLevelsWithNumbers, echo=FALSE}
target = 'Parties:'; target
indexes = c(1,2,3,4,5,6); indexes
levels(gles$f.vote)
target = 'Political Wings:'; target
indexes = c(1,2,3); indexes
levels(gles$f.political_orientation)
```

```{r visualInteractionsImm, echo=FALSE}
#egoposition_immigration
par(mfrow=c(1,1))
boxplot(f.vote~egoposition_immigration,data=gles,
        main = "Association of f.vote and Egoposition Immigration")
```

```{r visualInteractionsPolInt, echo=FALSE}
#political_interest
par(mfrow=c(1,1))
boxplot(f.vote~political_interest,data=gles,
        main = "Association of f.vote and Political Interest")
```

```{r visualInteractionsIncome, echo=FALSE}
#income satisfaction
par(mfrow=c(1,1))
boxplot(f.vote~income,data=gles,
        main = "Association of f.vote and Income Satisfaction")
```

```{r visualInteractionsEast, echo=FALSE}
#East Germany
par(mfrow=c(1,1))
boxplot(f.vote~f.eastGermany,data=gles,
        main = "Association of f.vote and East Germany")
```

```{r visualInteractionsGender, echo=FALSE}
#Gender
par(mfrow=c(1,1))
boxplot(f.vote~f.gender,data=gles,
        main = "Association of f.vote and Gender")
```

```{r visualInteractionsImmW, echo=FALSE}
#egoposition_immigration
par(mfrow=c(1,1))
boxplot(f.political_orientation~egoposition_immigration,data=gles,
        main = "Association of Political Wings and Egoposition Immigration")
```

```{r visualInteractionsPolIntW, echo=FALSE}
#political_interest
par(mfrow=c(1,1))
boxplot(f.political_orientation~political_interest,data=gles,
        main = "Association of Political Wings and Political Interest")
```

```{r visualInteractionsIncomeW, echo=FALSE}
#income satisfaction
par(mfrow=c(1,1))
boxplot(f.political_orientation~income,data=gles,
        main = "Association of Political Wings and Income Satisfaction")
```

```{r visualInteractionsEastW, echo=FALSE}
#East Germany
par(mfrow=c(1,1))
boxplot(f.political_orientation~f.eastGermany,data=gles,
        main = "Association of Political Wings and East Germany")
```

```{r visualInteractionsGenderW, echo=FALSE}
#Gender
par(mfrow=c(1,1))
boxplot(f.political_orientation~f.gender,data=gles,
        main = "Association of Political Wings and Gender")
```

```{r catdesF.Vote}
res.cat<-catdes(gles, 10) #11 for new factor
res.cat$category
```

```{r catdesF.political_orientation}
res.cat<-catdes(gles, 11) #11 for new factor
res.cat$category
```

## Modelling

### Comparison of Variables' Numerical and Categorical Representation

```{r egoposition_immigrationCheck}
nm1_imm_con <- multinom(f.vote~ egoposition_immigration, data=train)
nm1_imm_con_sq <- multinom(f.vote~ poly(egoposition_immigration,2), data=train)
nm1_imm_con_cb <- multinom(f.vote~ poly(egoposition_immigration,3), data=train)
nm1_imm_con_qd <- multinom(f.vote~ poly(egoposition_immigration,4), data=train)
nm1_imm_cat <- multinom(f.vote~ f.egoposition_immigration, data=train)
nm1_imm_cat_new <- multinom(f.vote~ f.Imm, data=train)

nm0$dev - nm1_imm_con$dev
nm0$dev - nm1_imm_con_sq$dev
nm0$dev - nm1_imm_con_cb$dev
nm0$dev - nm1_imm_con_qd$dev
nm0$dev - nm1_imm_cat$dev
nm0$dev - nm1_imm_cat_new$dev

Anova(nm1_imm_con, test="Chisq")
Anova(nm1_imm_con_sq, test="Chisq")
Anova(nm1_imm_con_cb, test="Chisq")
Anova(nm1_imm_con_qd, test="Chisq")
Anova(nm1_imm_cat, test="Chisq")
Anova(nm1_imm_cat_new, test="Chisq")

plot(allEffects(nm1_imm_con),ask=FALSE, main="Effects Imm Continuous")
plot(allEffects(nm1_imm_con_sq),ask=FALSE,main="Effects Imm Continuous Squared")
plot(allEffects(nm1_imm_con_cb),ask=FALSE, main="Effects Imm Continuous Cubed")
plot(allEffects(nm1_imm_con_qd),ask=FALSE, main="Effects Imm Continuous Quadratic")
plot(allEffects(nm1_imm_cat),ask=FALSE, main="Effects Imm Categorical")
plot(allEffects(nm1_imm_cat_new),ask=FALSE, main="Effects Imm Categorical")

AIC(nm0, nm1_imm_con, nm1_imm_con_sq, nm1_imm_con_cb, nm1_imm_con_qd, nm1_imm_cat, nm1_imm_cat_new)
# nm1_imm_con_cb is better concerning AIC but we lose 5 df that compared to new factor. New factor will be used finally.
step(nm1_imm_cat_new)
```

```{r political_interestCheck}
nm1_polint_con <- multinom(f.vote~ political_interest, data=train)
nm1_polint_con_sq <- multinom(f.vote~ poly(political_interest,2), data=train)
nm1_polint_con_cb <- multinom(f.vote~ poly(political_interest,3), data=train)
nm1_polint_con_qd <- multinom(f.vote~ poly(political_interest,4), data=train)
nm1_polint_cat <- multinom(f.vote~ f.political_interest, data=train)
nm1_polint_cat_new <- multinom(f.vote~ f.PolInt, data=train)

nm0$dev - nm1_polint_con$dev
nm0$dev - nm1_polint_con_sq$dev
nm0$dev - nm1_polint_con_cb$dev
nm0$dev - nm1_polint_con_qd$dev
nm0$dev - nm1_polint_cat$dev
nm0$dev - nm1_polint_cat_new$dev

anova(nm1_polint_con, nm1_polint_con_sq, test="Chisq")
anova(nm1_polint_con_sq, nm1_polint_con_cb, test="Chisq")
anova(nm1_polint_con_cb, nm1_polint_con_qd, test="Chisq")


Anova(nm1_polint_con, test="Chisq")
Anova(nm1_polint_con_sq, test="Chisq")
Anova(nm1_polint_con_cb, test="Chisq")
Anova(nm1_polint_con_qd, test="Chisq")
Anova(nm1_polint_cat, test="Chisq")
Anova(nm1_polint_cat_new, test="Chisq")

plot(allEffects(nm1_polint_con),ask=FALSE, main="Effects Pol Int Continuous")
plot(allEffects(nm1_polint_con_sq),ask=FALSE,main="Effects Pol Int Continuous Squared")
plot(allEffects(nm1_polint_con_cb),ask=FALSE, main="Effects Pol Int Continuous Cubed")
plot(allEffects(nm1_polint_con_qd),ask=FALSE, main="Effects Pol Int Continuous Quadratic")
plot(allEffects(nm1_polint_cat),ask=FALSE, main="Effects Pol Int Categorical")
plot(allEffects(nm1_polint_cat_new),ask=FALSE, main="Effects Pol Int Categorical")

AIC(nm0, nm1_polint_con, nm1_polint_con_sq, nm1_polint_con_cb, nm1_polint_con_qd, nm1_polint_cat, nm1_polint_cat_new)
# nm1_polint_con_sq is better, but in general politican interest does not provide predictability power, null model is better in most of the cases. Political interest will be used in squared form.
step(nm1_polint_con_sq)
```

```{r incomeCheck}
nm1_inc_con <- multinom(f.vote~ income, data=train)
nm1_inc_con_sq <- multinom(f.vote~ poly(income,2), data=train)
nm1_inc_con_cb <- multinom(f.vote~ poly(income,3), data=train)
nm1_inc_con_qd <- multinom(f.vote~ poly(income,4), data=train)
nm1_inc_cat <- multinom(f.vote~ f.income, data=train)
nm1_inc_cat_new <- multinom(f.vote~ f.IncSat, data=train)

nm0$dev - nm1_inc_con$dev
nm0$dev - nm1_inc_con_sq$dev
nm0$dev - nm1_inc_con_cb$dev
nm0$dev - nm1_inc_con_qd$dev
nm0$dev - nm1_inc_cat$dev
nm0$dev - nm1_inc_cat_new$dev

anova(nm1_inc_con, nm1_inc_con_sq, test="Chisq")
anova(nm1_inc_con_sq, nm1_inc_con_cb, test="Chisq")
anova(nm1_inc_con_cb, nm1_inc_con_qd, test="Chisq")

Anova(nm1_inc_con, test="Chisq")
Anova(nm1_inc_con_sq, test="Chisq")
Anova(nm1_inc_con_cb, test="Chisq")
Anova(nm1_inc_con_qd, test="Chisq")
Anova(nm1_inc_cat, test="Chisq")
Anova(nm1_inc_cat_new, test="Chisq")

plot(allEffects(nm1_inc_con),ask=FALSE, main="Effects Inc Sat Continuous")
plot(allEffects(nm1_inc_con_sq),ask=FALSE,main="Effects Inc Sat Continuous Squared")
plot(allEffects(nm1_inc_con_cb),ask=FALSE, main="Effects Inc Sat Continuous Cubed")
plot(allEffects(nm1_inc_con_qd),ask=FALSE, main="Effects Inc Sat Continuous Quadratic")
plot(allEffects(nm1_inc_cat),ask=FALSE, main="Effects Inc Sat Categorical")
plot(allEffects(nm1_inc_cat_new),ask=FALSE, main="Effects Inc Sat Categorical")

AIC(nm0, nm1_inc_con, nm1_inc_con_sq, nm1_inc_con_cb, nm1_inc_con_qd, nm1_inc_cat, nm1_imm_cat_new)
# nm1_imm_cat_new is better, income satisfaction will be used as the new factor generated
step(nm1_imm_cat_new)
```

### Quality Info Model m0
